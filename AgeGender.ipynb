{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgeGender.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/droidadroit/age-and-gender-classification/blob/master/AgeGender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XCz5QH4dlh_H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "O5NLRAhllX29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mounting the drive"
      ]
    },
    {
      "metadata": {
        "id": "uRVNRKKSVNLK",
        "colab_type": "code",
        "outputId": "b1e9a919-d750-46f2-bb19-24e45ffa213e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v93fXs2y7sxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Directory structure\n",
        "\n",
        "content  \n",
        "---- gdrive  \n",
        "-------- My Drive  \n",
        "------------ **AgeGenderClassification**  \n",
        "---------------- **data**  \n",
        "---------------- **models**  \n",
        "---------------- **results**  \n",
        "---------------- **AgeGender.ipynb**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wQvenRKomUkx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "MRHSqYujmgn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkNgiJoSm87s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "BRaqXIPonB8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd.variable as Variable\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as utils\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wIv9zyxtHxt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1yuk49NUPoa",
        "colab_type": "code",
        "outputId": "0df81817-2a10-4576-b6b9-f81675455351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==5.3.0\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow==5.3.0 in /usr/local/lib/python3.6/dist-packages (5.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0_z6Q972xi32",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing dataloaders"
      ]
    },
    {
      "metadata": {
        "id": "s_KtxziRPrVI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Raw data**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8csd2D2v4-0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading data\n",
        "\n",
        "\n",
        "We use the Adience dataset consisting unfiltered faces ([Link](http://www.cslab.openu.ac.il/download/adiencedb/AdienceBenchmarkOfUnfilteredFacesForGenderAndAgeClassification/aligned.tar.gz)).  \n",
        "Download it in the **data** directory. Then, we unzip it."
      ]
    },
    {
      "metadata": {
        "id": "4Tqb-HEKTLLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!wget --user adiencedb --password adience http://www.cslab.openu.ac.il/download/adiencedb/AdienceBenchmarkOfUnfilteredFacesForGenderAndAgeClassification/aligned.tar.gz -P \"/content/gdrive/My Drive/AgeGenderClassification/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPeBSiNqimxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!tar xvzf \"/content/gdrive/My Drive/AgeGenderClassification/data/aligned.tar.gz\" -C \"/content/gdrive/My Drive/AgeGenderClassification/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88F5gWj5o4bh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading folds\n",
        "\n",
        "All five folds used are present [here](https://github.com/GilLevi/AgeGenderDeepLearning/tree/master/Folds/train_val_txt_files_per_fold). Download the **train_val_txt_files_per_fold** folder and place it in the **data** directory.\n"
      ]
    },
    {
      "metadata": {
        "id": "2VtoAJghnpLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ]
    },
    {
      "metadata": {
        "id": "squb12xguXqd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_FOLDS = \"/content/gdrive/My Drive/AgeGenderClassification/data/train_val_txt_files_per_fold\"\n",
        "PATH_TO_DATA = \"/content/gdrive/My Drive/AgeGenderClassification/data\"\n",
        "PATH_TO_IMAGE_FOLDERS = PATH_TO_DATA + \"/aligned\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2Czi4va4QKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating a Dataset class\n",
        "\n",
        "We create a class **`AdienceDataset`** that extends **`Dataset`**."
      ]
    },
    {
      "metadata": {
        "id": "BiUufbSinr1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdienceDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, txt_file, root_dir, transform):\n",
        "        self.txt_file = txt_file\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.data = self.read_from_txt_file()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def read_from_txt_file(self):\n",
        "        data = []\n",
        "        f = open(self.txt_file)\n",
        "        for line in f.readlines():\n",
        "            image_file, label = line.split()\n",
        "            label = int(label)\n",
        "            if 'gender' in self.txt_file:\n",
        "                label += 8\n",
        "            data.append((image_file, label))\n",
        "        return data\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name, label = self.data[idx]\n",
        "        image = Image.open(self.root_dir + '/' + img_name)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return {\n",
        "            'image': image,\n",
        "            'label': label\n",
        "        }         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WAx-8hZNsXFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transforms"
      ]
    },
    {
      "metadata": {
        "id": "_wMCsfG1sY4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transforms_list = [\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "]\n",
        "\n",
        "transforms_dict = {\n",
        "    'train': {\n",
        "        0: list(transforms_list[i] for i in [0, 1, 3]),\n",
        "        1: list(transforms_list[i] for i in [0, 1, 2, 3])\n",
        "    },\n",
        "    'val': {\n",
        "        0: list(transforms_list[i] for i in [0, 1, 3])\n",
        "    },\n",
        "    'test': {\n",
        "        0: list(transforms_list[i] for i in [0, 1, 3])\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iURni95m4sGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ]
    },
    {
      "metadata": {
        "id": "ox_PryLS4u2x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_dataloader(s, c, fold, transform_index, minibatch_size):\n",
        "\n",
        "    txt_file = f'{PATH_TO_FOLDS}/test_fold_is_{fold}/{c}_{s}.txt'\n",
        "    root_dir = PATH_TO_IMAGE_FOLDERS\n",
        "    \n",
        "    transformed_dataset = AdienceDataset(txt_file, root_dir,\n",
        "                                         transforms.Compose(transforms_dict[s][transform_index]))\n",
        "    dataloader = DataLoader(transformed_dataset, batch_size=5, shuffle=False, num_workers=4)\n",
        "    \n",
        "    return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lrstEuSm1qH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Network"
      ]
    },
    {
      "metadata": {
        "id": "o9feSnLcFq2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "PATH_TO_MODELS = \"/content/gdrive/My Drive/AgeGenderClassification/models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZh1psZ6mY6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the network"
      ]
    },
    {
      "metadata": {
        "id": "pd91hyHvmhYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Conv layer 1\n",
        "        self.conv1 = nn.Conv2d(3, 96, 7, stride = 4, padding = 1)\n",
        "        self.pool1 = nn.MaxPool2d(3, stride = 2, padding = 1)\n",
        "        self.norm1 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n",
        "        \n",
        "        # Conv layer 2\n",
        "        self.conv2 = nn.Conv2d(96, 256, 5, stride = 1, padding = 2)\n",
        "        self.pool2 = nn.MaxPool2d(3, stride = 2, padding = 1)\n",
        "        self.norm2 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n",
        "        \n",
        "        # Conv layer 3\n",
        "        self.conv3 = nn.Conv2d(256, 384, 3, stride = 1, padding = 1)\n",
        "        self.pool3 = nn.MaxPool2d(3, stride = 2, padding = 1)\n",
        "        self.norm3 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n",
        "        \n",
        "        # FC 1\n",
        "        self.fc1 = nn.Linear(18816, 512)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        # FC 2\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "  \n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "    \n",
        "        self.apply(weights_init)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = F.leaky_relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.norm2(x)\n",
        "      \n",
        "        x = F.leaky_relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.norm3(x)\n",
        "      \n",
        "        x = x.view(-1, 18816)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.dropout1(x)\n",
        "      \n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.dropout2(x)\n",
        "      \n",
        "        x = F.log_softmax(self.fc3(x))\n",
        "  \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uaI0Bs-Rxio-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, mean=0, std=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCTDc4XEyqOq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "w5Vm2Tb2yzYT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "minibatch_size = 5\n",
        "num_epochs = 12\n",
        "criterion = nn.NLLLoss()\n",
        "lr = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5NPiENkmpYl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the network"
      ]
    },
    {
      "metadata": {
        "id": "NnkM7TgymrED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, train_dataloader, epochs, filename, checkpoint_frequency, val_dataloader=None):\n",
        "    \n",
        "    optimizer = optim.Adam(net.parameters(), lr)\n",
        "    validation_loss = []\n",
        "    checkpoint = 0\n",
        "    iteration = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            images, labels = batch['image'].to(device), batch['label'].to(device)\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                print(i, 'train')\n",
        "                        \n",
        "            if iteration % checkpoint_frequency == 0 and val_dataloader is not None:\n",
        "                validation_loss.append(validate(net, val_dataloader))\n",
        "                print(f'minibatch:{i}, epoch:{epoch}, iteration:{iteration}, validation_error:{validation_loss[-1]}')\n",
        "                save_network(net, f'{filename}_checkpoint{checkpoint}')\n",
        "                checkpoint += 1\n",
        "            \n",
        "            iteration += 1\n",
        "\n",
        "    return net, validation_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7WndciFmv0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ]
    },
    {
      "metadata": {
        "id": "8Es1uGKQnK9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(net, dataloader):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            images, labels = batch['image'].to(device), batch['label'].to(device)\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += float(loss.item())\n",
        "            if i % 100 == 0:\n",
        "                print(i, 'validate')\n",
        "\n",
        "    return total_loss/(i+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAto0iO4zPLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "fCUCNrL0zR3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(net, dataloader, c):\n",
        "    result = {\n",
        "        'exact_match': 0,\n",
        "        'total': 0\n",
        "    }\n",
        "    if c == 'age':\n",
        "        result['one_off_match'] = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            images, labels = batch['image'].to(device), batch['label'].to(device)\n",
        "            outputs = net(images)\n",
        "            outputs = torch.tensor(list(map(lambda x: torch.max(x, 0)[1], outputs))).to(device)\n",
        "            result['total'] += len(outputs)\n",
        "            result['exact_match'] += sum(outputs == labels).item()\n",
        "            if c == 'age':\n",
        "                result['one_off_match'] += (sum(outputs==labels) +\n",
        "                                            sum(outputs==labels-1) +\n",
        "                                            sum(outputs==labels+1)).item()\n",
        "            if i % 100 == 0:\n",
        "                print(i, 'test')\n",
        "\n",
        "    return result           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSq61rZ-yOPZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving the network"
      ]
    },
    {
      "metadata": {
        "id": "YzgCR7VqyQU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_network(net, filename):\n",
        "    torch.save(net.state_dict(), f'{PATH_TO_MODELS}/{filename}.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hl1owOOw0ZeU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ]
    },
    {
      "metadata": {
        "id": "LkGcdSij98nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the network and save the models"
      ]
    },
    {
      "metadata": {
        "id": "ravxG5ce0bz0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_save(c, fold, train_transform_index, checkpoint_frequency=500):\n",
        "    trained_net, validation_loss = train(\n",
        "        Net().to(device),\n",
        "        get_dataloader('train', c, fold, train_transform_index, minibatch_size),\n",
        "        num_epochs,\n",
        "        f'{fold}_{c}_train_{train_transform_index}',\n",
        "        checkpoint_frequency,\n",
        "        get_dataloader('val', c, fold, 0, minibatch_size)\n",
        "    )\n",
        "    \n",
        "    plt.plot(list(map(lambda x: checkpoint_frequency * x, (list(range(0, len(validation_loss)))))), validation_loss)\n",
        "    plt.xlabel('iterations')\n",
        "    plt.ylabel('validation loss')\n",
        "    plt.show()\n",
        "    for index, l in enumerate(validation_loss):\n",
        "        print(f'iteration:{index * checkpoint_frequency}, validation_loss={l}')\n",
        "           \n",
        "    return validation_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPthBe2b-Ap2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Choose the best model"
      ]
    },
    {
      "metadata": {
        "id": "1bYLxmb_JupM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def choose_best_model(c, fold, train_transform_index, validation_loss):\n",
        "    index = validation_loss.index(min(validation_loss))\n",
        "    filename = f'{fold}_{c}_train_{train_transform_index}'\n",
        "    for file in os.listdir(PATH_TO_MODELS):\n",
        "        if file.startswith(filename):\n",
        "            if file.startswith(f'{filename}_checkpoint{index}'):\n",
        "                pass\n",
        "            else:\n",
        "                os.remove(f'{PATH_TO_MODELS}/{file}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghOw4Hnpa2wg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_best_model_filename(c, fold, train_transform_index):\n",
        "    start_of_filename = f'{fold}_{c}_train_{train_transform_index}_checkpoint'\n",
        "    for file in os.listdir(PATH_TO_MODELS):\n",
        "        if file.startswith(start_of_filename):\n",
        "            return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cfin5ix8-Esn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get performance of a model"
      ]
    },
    {
      "metadata": {
        "id": "Qo_p5XeGUVmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_performance(c, fold, train_transform_index):\n",
        "    filename = get_best_model_filename(c, fold, train_transform_index)\n",
        "    net = Net().to(device)\n",
        "    net.load_state_dict(torch.load(f'{PATH_TO_MODELS}/{filename}'))\n",
        "    performance = test(\n",
        "        net,\n",
        "        get_dataloader('test', c, fold, 0, minibatch_size),\n",
        "        c\n",
        "    )\n",
        "    if c == 'age':\n",
        "        return {\n",
        "            'accuracy': performance['exact_match']/performance['total'],\n",
        "            'one-off accuracy': performance['one_off_match']/performance['total']\n",
        "        }\n",
        "    elif c == 'gender':\n",
        "        return {\n",
        "            'accuracy': performance['exact_match']/performance['total']\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUyMnXqwauw9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_validation_error(c, fold, train_transform_index):\n",
        "    filename = get_best_model_filename(c, fold, train_transform_index)\n",
        "    net = Net().to(device)\n",
        "    net.load_state_dict(torch.load(f'{PATH_TO_MODELS}/{filename}'))\n",
        "    return validate(net, get_dataloader('val', c, fold, 0, minibatch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l89AKPw-0eCZ",
        "colab_type": "code",
        "outputId": "821a5fe5-d2d7-45f8-a9ed-2e0992e5d97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3811
        }
      },
      "cell_type": "code",
      "source": [
        "validation_loss = train_save(c='age', fold=3, train_transform_index=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:0, epoch:0, iteration:0, validation_error:2.306431763792691\n",
            "100 train\n",
            "200 train\n",
            "300 train\n",
            "400 train\n",
            "500 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:500, epoch:0, iteration:500, validation_error:1.9387054994498214\n",
            "600 train\n",
            "700 train\n",
            "800 train\n",
            "900 train\n",
            "1000 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1000, epoch:0, iteration:1000, validation_error:1.9742665009139335\n",
            "1100 train\n",
            "1200 train\n",
            "1300 train\n",
            "1400 train\n",
            "1500 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1500, epoch:0, iteration:1500, validation_error:1.931147381867448\n",
            "1600 train\n",
            "1700 train\n",
            "1800 train\n",
            "1900 train\n",
            "2000 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:2000, epoch:0, iteration:2000, validation_error:2.077457299379453\n",
            "2100 train\n",
            "2200 train\n",
            "2300 train\n",
            "2400 train\n",
            "2500 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:2500, epoch:0, iteration:2500, validation_error:1.8833135456255037\n",
            "0 train\n",
            "100 train\n",
            "200 train\n",
            "300 train\n",
            "400 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:401, epoch:1, iteration:3000, validation_error:1.8232565718154385\n",
            "500 train\n",
            "600 train\n",
            "700 train\n",
            "800 train\n",
            "900 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:901, epoch:1, iteration:3500, validation_error:1.7169428171768581\n",
            "1000 train\n",
            "1100 train\n",
            "1200 train\n",
            "1300 train\n",
            "1400 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1401, epoch:1, iteration:4000, validation_error:1.5686663630074018\n",
            "1500 train\n",
            "1600 train\n",
            "1700 train\n",
            "1800 train\n",
            "1900 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1901, epoch:1, iteration:4500, validation_error:1.494824592177182\n",
            "2000 train\n",
            "2100 train\n",
            "2200 train\n",
            "2300 train\n",
            "2400 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:2401, epoch:1, iteration:5000, validation_error:1.4426027940560693\n",
            "2500 train\n",
            "0 train\n",
            "100 train\n",
            "200 train\n",
            "300 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:302, epoch:2, iteration:5500, validation_error:1.457284297436884\n",
            "400 train\n",
            "500 train\n",
            "600 train\n",
            "700 train\n",
            "800 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:802, epoch:2, iteration:6000, validation_error:1.3897595048358995\n",
            "900 train\n",
            "1000 train\n",
            "1100 train\n",
            "1200 train\n",
            "1300 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1302, epoch:2, iteration:6500, validation_error:1.3437751194793883\n",
            "1400 train\n",
            "1500 train\n",
            "1600 train\n",
            "1700 train\n",
            "1800 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1802, epoch:2, iteration:7000, validation_error:1.369531607791169\n",
            "1900 train\n",
            "2000 train\n",
            "2100 train\n",
            "2200 train\n",
            "2300 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:2302, epoch:2, iteration:7500, validation_error:1.3170991433809882\n",
            "2400 train\n",
            "2500 train\n",
            "0 train\n",
            "100 train\n",
            "200 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:203, epoch:3, iteration:8000, validation_error:1.313892132921578\n",
            "300 train\n",
            "400 train\n",
            "500 train\n",
            "600 train\n",
            "700 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:703, epoch:3, iteration:8500, validation_error:1.3929737689968658\n",
            "800 train\n",
            "900 train\n",
            "1000 train\n",
            "1100 train\n",
            "1200 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1203, epoch:3, iteration:9000, validation_error:1.2739983331667233\n",
            "1300 train\n",
            "1400 train\n",
            "1500 train\n",
            "1600 train\n",
            "1700 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1703, epoch:3, iteration:9500, validation_error:1.2695548731374413\n",
            "1800 train\n",
            "1900 train\n",
            "2000 train\n",
            "2100 train\n",
            "2200 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:2203, epoch:3, iteration:10000, validation_error:1.2489673288105285\n",
            "2300 train\n",
            "2400 train\n",
            "2500 train\n",
            "0 train\n",
            "100 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:104, epoch:4, iteration:10500, validation_error:1.2178725178723466\n",
            "200 train\n",
            "300 train\n",
            "400 train\n",
            "500 train\n",
            "600 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:604, epoch:4, iteration:11000, validation_error:1.2121312886680642\n",
            "700 train\n",
            "800 train\n",
            "900 train\n",
            "1000 train\n",
            "1100 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1104, epoch:4, iteration:11500, validation_error:1.196453709818729\n",
            "1200 train\n",
            "1300 train\n",
            "1400 train\n",
            "1500 train\n",
            "1600 train\n",
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "minibatch:1604, epoch:4, iteration:12000, validation_error:1.2029268660978094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CrvElwP6Q7Vu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "choose_best_model('age', 3, 1, validation_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6ydWwtfZKXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "63b68ec7-b360-48d8-d15d-395a9c53d131"
      },
      "cell_type": "code",
      "source": [
        "performance = get_performance('age', 3, 1)\n",
        "print(performance)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 test\n",
            "100 test\n",
            "200 test\n",
            "300 test\n",
            "400 test\n",
            "500 test\n",
            "600 test\n",
            "{'accuracy': 0.5327942497753818, 'one-off accuracy': 0.8496555855046422}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rn-yaDvyagh-",
        "colab_type": "code",
        "outputId": "343108ec-3432-40c0-a9a0-8946fc0a1ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "error = get_validation_error('age', 3, 1)\n",
        "print(error)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 validate\n",
            "100 validate\n",
            "200 validate\n",
            "0.9154792693020268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1wNIEqxlcOSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# started at 17:43"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}